{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression: Beginner Theory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is quite mathematical since we want to understand this machine learning algorithm pretty well. We'll work with simple linear regression as a starting point where we predict one variable from another variable and then we'll look at multiple linear regression where we can predict one output variable from multiple input variables. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The main concept is to make our predictions as close to the actual values as possible. \n",
    "\n",
    "So how can we make this happen? \n",
    "\n",
    "We want to see how far away our predictions are from the actual values, but this won't be a simple subtraction because sometimes the prediction can be higher than the original and when we want to add up all the differences, it can give us an answer that is close to zero. \n",
    "\n",
    "In order to deal with this, we square the differences before adding up the squared differences. \n",
    "\n",
    "$$ E = \\sum_{i=1}^{N}{(y_i - \\hat{y_i})^2} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the equation above, $ y_i $ represents our actual output values and $ \\hat{y_i} $ represents our prediction values. \n",
    "\n",
    "A perfect linear regression model is where every single $ \\hat{y_i} $ is equal to the $ y_i $ . In reality, this will be pretty much impossible, but what we can do is try and adjust the model's parameters so it can try and minimize this error to be as close to zero as possible. \n",
    "\n",
    "So let's look at a simple linear regression model.\n",
    "\n",
    "From high school, you are probably used to $$ y = mx + b $$ . Linear regression works the same exact way because you are working with two parameters: the slope $ m $ and the bias term (intercept) $ b $ . We want to turn this into what a formal machine learning regression model looks like:\n",
    "\n",
    "$$ \\hat{y_i} = \\beta_1 x_i + \\beta_0   $$  \n",
    "\n",
    "In the above equation, $ \\beta_1 $ is the same as $ m $ and $ \\beta_0 $ is the same as the intercept $ b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
